{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC 483 - Project 3\n",
    "\n",
    "Our submission for CPSC 483, Project 3, CSUF Fall 2020.\n",
    "\n",
    "## Group Members\n",
    "\n",
    "* Brandon Xue (brandonx@csu.fullerton.edu)\n",
    "* Mike Peralta (mikeperalta@csu.fullerton.edu)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 - Loading Boston\n",
    "Load and examine the Boston dataset’s features, target values, and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston data frame features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...    ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0   \n",
       "\n",
       "     PTRATIO       B  LSTAT  \n",
       "0       15.3  396.90   4.98  \n",
       "1       17.8  396.90   9.14  \n",
       "2       17.8  392.83   4.03  \n",
       "3       18.7  394.63   2.94  \n",
       "4       18.7  396.90   5.33  \n",
       "..       ...     ...    ...  \n",
       "501     21.0  391.99   9.67  \n",
       "502     21.0  396.90   9.08  \n",
       "503     21.0  396.90   5.64  \n",
       "504     21.0  393.45   6.48  \n",
       "505     21.0  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boston dataset's target values:\n",
      "[24.  21.6 34.7 33.4 36.2 28.7 22.9 27.1 16.5 18.9 15.  18.9 21.7 20.4\n",
      " 18.2 19.9 23.1 17.5 20.2 18.2 13.6 19.6 15.2 14.5 15.6 13.9 16.6 14.8\n",
      " 18.4 21.  12.7 14.5 13.2 13.1 13.5 18.9 20.  21.  24.7 30.8 34.9 26.6\n",
      " 25.3 24.7 21.2 19.3 20.  16.6 14.4 19.4 19.7 20.5 25.  23.4 18.9 35.4\n",
      " 24.7 31.6 23.3 19.6 18.7 16.  22.2 25.  33.  23.5 19.4 22.  17.4 20.9\n",
      " 24.2 21.7 22.8 23.4 24.1 21.4 20.  20.8 21.2 20.3 28.  23.9 24.8 22.9\n",
      " 23.9 26.6 22.5 22.2 23.6 28.7 22.6 22.  22.9 25.  20.6 28.4 21.4 38.7\n",
      " 43.8 33.2 27.5 26.5 18.6 19.3 20.1 19.5 19.5 20.4 19.8 19.4 21.7 22.8\n",
      " 18.8 18.7 18.5 18.3 21.2 19.2 20.4 19.3 22.  20.3 20.5 17.3 18.8 21.4\n",
      " 15.7 16.2 18.  14.3 19.2 19.6 23.  18.4 15.6 18.1 17.4 17.1 13.3 17.8\n",
      " 14.  14.4 13.4 15.6 11.8 13.8 15.6 14.6 17.8 15.4 21.5 19.6 15.3 19.4\n",
      " 17.  15.6 13.1 41.3 24.3 23.3 27.  50.  50.  50.  22.7 25.  50.  23.8\n",
      " 23.8 22.3 17.4 19.1 23.1 23.6 22.6 29.4 23.2 24.6 29.9 37.2 39.8 36.2\n",
      " 37.9 32.5 26.4 29.6 50.  32.  29.8 34.9 37.  30.5 36.4 31.1 29.1 50.\n",
      " 33.3 30.3 34.6 34.9 32.9 24.1 42.3 48.5 50.  22.6 24.4 22.5 24.4 20.\n",
      " 21.7 19.3 22.4 28.1 23.7 25.  23.3 28.7 21.5 23.  26.7 21.7 27.5 30.1\n",
      " 44.8 50.  37.6 31.6 46.7 31.5 24.3 31.7 41.7 48.3 29.  24.  25.1 31.5\n",
      " 23.7 23.3 22.  20.1 22.2 23.7 17.6 18.5 24.3 20.5 24.5 26.2 24.4 24.8\n",
      " 29.6 42.8 21.9 20.9 44.  50.  36.  30.1 33.8 43.1 48.8 31.  36.5 22.8\n",
      " 30.7 50.  43.5 20.7 21.1 25.2 24.4 35.2 32.4 32.  33.2 33.1 29.1 35.1\n",
      " 45.4 35.4 46.  50.  32.2 22.  20.1 23.2 22.3 24.8 28.5 37.3 27.9 23.9\n",
      " 21.7 28.6 27.1 20.3 22.5 29.  24.8 22.  26.4 33.1 36.1 28.4 33.4 28.2\n",
      " 22.8 20.3 16.1 22.1 19.4 21.6 23.8 16.2 17.8 19.8 23.1 21.  23.8 23.1\n",
      " 20.4 18.5 25.  24.6 23.  22.2 19.3 22.6 19.8 17.1 19.4 22.2 20.7 21.1\n",
      " 19.5 18.5 20.6 19.  18.7 32.7 16.5 23.9 31.2 17.5 17.2 23.1 24.5 26.6\n",
      " 22.9 24.1 18.6 30.1 18.2 20.6 17.8 21.7 22.7 22.6 25.  19.9 20.8 16.8\n",
      " 21.9 27.5 21.9 23.1 50.  50.  50.  50.  50.  13.8 13.8 15.  13.9 13.3\n",
      " 13.1 10.2 10.4 10.9 11.3 12.3  8.8  7.2 10.5  7.4 10.2 11.5 15.1 23.2\n",
      "  9.7 13.8 12.7 13.1 12.5  8.5  5.   6.3  5.6  7.2 12.1  8.3  8.5  5.\n",
      " 11.9 27.9 17.2 27.5 15.  17.2 17.9 16.3  7.   7.2  7.5 10.4  8.8  8.4\n",
      " 16.7 14.2 20.8 13.4 11.7  8.3 10.2 10.9 11.   9.5 14.5 14.1 16.1 14.3\n",
      " 11.7 13.4  9.6  8.7  8.4 12.8 10.5 17.1 18.4 15.4 10.8 11.8 14.9 12.6\n",
      " 14.1 13.  13.4 15.2 16.1 17.8 14.9 14.1 12.7 13.5 14.9 20.  16.4 17.7\n",
      " 19.5 20.2 21.4 19.9 19.  19.1 19.1 20.1 19.9 19.6 23.2 29.8 13.8 13.3\n",
      " 16.7 12.  14.6 21.4 23.  23.7 25.  21.8 20.6 21.2 19.1 20.6 15.2  7.\n",
      "  8.1 13.6 20.1 21.8 24.5 23.1 19.7 18.3 21.2 17.5 16.8 22.4 20.6 23.9\n",
      " 22.  11.9]\n",
      "\n",
      "Boston dataset's description:\n",
      ".. _boston_dataset:\n",
      "\n",
      "Boston house prices dataset\n",
      "---------------------------\n",
      "\n",
      "**Data Set Characteristics:**  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/housing/\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      ".. topic:: References\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import some libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "# Load the boston dataset, and immediately shove it into a Pandas data frame, because it's cooler\n",
    "boston = load_boston()\n",
    "boston_frame = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "print(\"Boston data frame features\")\n",
    "display(boston_frame)\n",
    "print()\n",
    "print(\"Boston dataset's target values:\")\n",
    "print(boston.target)\n",
    "print()\n",
    "print(\"Boston dataset's description:\")\n",
    "print(boston.DESCR)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2 - CRIM as the New Target t\n",
    "Save CRIM as the new target value t, and drop the column CRIM from X. Add the target value MEDV to X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CRIM as the new t:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0      0.00632\n",
       "1      0.02731\n",
       "2      0.02729\n",
       "3      0.03237\n",
       "4      0.06905\n",
       "        ...   \n",
       "501    0.06263\n",
       "502    0.04527\n",
       "503    0.06076\n",
       "504    0.10959\n",
       "505    0.04741\n",
       "Name: CRIM, Length: 506, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Boston data frame after removing CRIM and adding MEDV:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0    18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0     15.3   \n",
       "1     0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0     17.8   \n",
       "2     0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0     17.8   \n",
       "3     0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0     18.7   \n",
       "4     0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0     18.7   \n",
       "..    ...    ...   ...    ...    ...   ...     ...  ...    ...      ...   \n",
       "501   0.0  11.93   0.0  0.573  6.593  69.1  2.4786  1.0  273.0     21.0   \n",
       "502   0.0  11.93   0.0  0.573  6.120  76.7  2.2875  1.0  273.0     21.0   \n",
       "503   0.0  11.93   0.0  0.573  6.976  91.0  2.1675  1.0  273.0     21.0   \n",
       "504   0.0  11.93   0.0  0.573  6.794  89.3  2.3889  1.0  273.0     21.0   \n",
       "505   0.0  11.93   0.0  0.573  6.030  80.8  2.5050  1.0  273.0     21.0   \n",
       "\n",
       "          B  LSTAT  MEDV  \n",
       "0    396.90   4.98  24.0  \n",
       "1    396.90   9.14  21.6  \n",
       "2    392.83   4.03  34.7  \n",
       "3    394.63   2.94  33.4  \n",
       "4    396.90   5.33  36.2  \n",
       "..      ...    ...   ...  \n",
       "501  391.99   9.67  22.4  \n",
       "502  396.90   9.08  20.6  \n",
       "503  396.90   5.64  23.9  \n",
       "504  393.45   6.48  22.0  \n",
       "505  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Let's redo the pull from the boston dataset into the panda dataframe,\n",
    "# so each run of this block is clean\n",
    "boston_frame = pd.DataFrame(data=boston.data, columns=boston.feature_names)\n",
    "\n",
    "# Set CRIM as the target value t.\n",
    "# I don't think I want to jam it into the original boston dataset,\n",
    "#  so I'm going to just going to take this literally and save it as \"t\"\n",
    "t = boston_frame[\"CRIM\"]\n",
    "print(\"CRIM as the new t:\")\n",
    "display(t)\n",
    "print()\n",
    "\n",
    "# Delete the CRIM column from the data frame\n",
    "del boston_frame[\"CRIM\"]\n",
    "# Add the old target value as MEDV to the features data frame\n",
    "boston_frame[\"MEDV\"] = boston.target\n",
    "print(\"Boston data frame after removing CRIM and adding MEDV:\")\n",
    "display(boston_frame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3 - Split Training/Testing Sets\n",
    "Use [sklearn.model_selection.train_test_split()](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) to split the features and target values into separate training and test sets. Use 80% of the original data as a training set, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>45.0</td>\n",
       "      <td>3.44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.951</td>\n",
       "      <td>21.5</td>\n",
       "      <td>6.4798</td>\n",
       "      <td>5.0</td>\n",
       "      <td>398.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>377.68</td>\n",
       "      <td>5.10</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.943</td>\n",
       "      <td>97.4</td>\n",
       "      <td>1.8773</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>363.43</td>\n",
       "      <td>4.59</td>\n",
       "      <td>41.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.458</td>\n",
       "      <td>98.9</td>\n",
       "      <td>2.1185</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>395.04</td>\n",
       "      <td>12.60</td>\n",
       "      <td>19.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>20.0</td>\n",
       "      <td>3.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "      <td>7.203</td>\n",
       "      <td>81.8</td>\n",
       "      <td>2.1121</td>\n",
       "      <td>5.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>392.80</td>\n",
       "      <td>9.59</td>\n",
       "      <td>33.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.655</td>\n",
       "      <td>6.209</td>\n",
       "      <td>65.4</td>\n",
       "      <td>2.9634</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>13.22</td>\n",
       "      <td>21.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.0</td>\n",
       "      <td>21.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>6.454</td>\n",
       "      <td>98.4</td>\n",
       "      <td>1.8498</td>\n",
       "      <td>4.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>394.08</td>\n",
       "      <td>14.59</td>\n",
       "      <td>17.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>6.202</td>\n",
       "      <td>78.7</td>\n",
       "      <td>1.8629</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>18.82</td>\n",
       "      <td>14.52</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.91</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448</td>\n",
       "      <td>5.399</td>\n",
       "      <td>95.3</td>\n",
       "      <td>5.8700</td>\n",
       "      <td>3.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>396.90</td>\n",
       "      <td>30.81</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.693</td>\n",
       "      <td>5.531</td>\n",
       "      <td>85.4</td>\n",
       "      <td>1.6074</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>329.46</td>\n",
       "      <td>27.38</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>404 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS    NOX     RM   AGE     DIS   RAD    TAX  PTRATIO  \\\n",
       "190  45.0   3.44   0.0  0.437  6.951  21.5  6.4798   5.0  398.0     15.2   \n",
       "157   0.0  19.58   0.0  0.605  6.943  97.4  1.8773   5.0  403.0     14.7   \n",
       "130   0.0  21.89   0.0  0.624  6.458  98.9  2.1185   4.0  437.0     21.2   \n",
       "260  20.0   3.97   0.0  0.647  7.203  81.8  2.1121   5.0  264.0     13.0   \n",
       "464   0.0  18.10   0.0  0.655  6.209  65.4  2.9634  24.0  666.0     20.2   \n",
       "..    ...    ...   ...    ...    ...   ...     ...   ...    ...      ...   \n",
       "137   0.0  21.89   0.0  0.624  6.454  98.4  1.8498   4.0  437.0     21.2   \n",
       "7    12.5   7.87   0.0  0.524  6.172  96.1  5.9505   5.0  311.0     15.2   \n",
       "427   0.0  18.10   0.0  0.679  6.202  78.7  1.8629  24.0  666.0     20.2   \n",
       "48    0.0   6.91   0.0  0.448  5.399  95.3  5.8700   3.0  233.0     17.9   \n",
       "404   0.0  18.10   0.0  0.693  5.531  85.4  1.6074  24.0  666.0     20.2   \n",
       "\n",
       "          B  LSTAT  MEDV  \n",
       "190  377.68   5.10  37.0  \n",
       "157  363.43   4.59  41.3  \n",
       "130  395.04  12.60  19.2  \n",
       "260  392.80   9.59  33.8  \n",
       "464  396.90  13.22  21.4  \n",
       "..      ...    ...   ...  \n",
       "137  394.08  14.59  17.1  \n",
       "7    396.90  19.15  27.1  \n",
       "427   18.82  14.52  10.9  \n",
       "48   396.90  30.81  14.4  \n",
       "404  329.46  27.38   8.5  \n",
       "\n",
       "[404 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "190     0.09068\n",
       "157     1.22358\n",
       "130     0.34006\n",
       "260     0.54011\n",
       "464     7.83932\n",
       "         ...   \n",
       "137     0.35233\n",
       "7       0.14455\n",
       "427    37.66190\n",
       "48      0.25387\n",
       "404    41.52920\n",
       "Name: TARGET, Length: 404, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.674</td>\n",
       "      <td>87.3</td>\n",
       "      <td>4.2390</td>\n",
       "      <td>4.0</td>\n",
       "      <td>307.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>380.23</td>\n",
       "      <td>11.98</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.445</td>\n",
       "      <td>7.820</td>\n",
       "      <td>36.9</td>\n",
       "      <td>3.4952</td>\n",
       "      <td>2.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>393.53</td>\n",
       "      <td>3.57</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.0</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>4.973</td>\n",
       "      <td>37.8</td>\n",
       "      <td>2.5194</td>\n",
       "      <td>4.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>18.4</td>\n",
       "      <td>350.45</td>\n",
       "      <td>12.64</td>\n",
       "      <td>16.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.966</td>\n",
       "      <td>93.4</td>\n",
       "      <td>6.8185</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>378.08</td>\n",
       "      <td>14.44</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>6.153</td>\n",
       "      <td>68.8</td>\n",
       "      <td>3.2797</td>\n",
       "      <td>3.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>387.11</td>\n",
       "      <td>13.15</td>\n",
       "      <td>29.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>6.066</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.7573</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>353.89</td>\n",
       "      <td>6.43</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679</td>\n",
       "      <td>6.434</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1.8347</td>\n",
       "      <td>24.0</td>\n",
       "      <td>666.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>27.25</td>\n",
       "      <td>29.05</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.515</td>\n",
       "      <td>5.869</td>\n",
       "      <td>46.3</td>\n",
       "      <td>5.2311</td>\n",
       "      <td>5.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>20.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.80</td>\n",
       "      <td>19.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>25.0</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>5.741</td>\n",
       "      <td>66.2</td>\n",
       "      <td>7.2254</td>\n",
       "      <td>8.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>395.11</td>\n",
       "      <td>13.15</td>\n",
       "      <td>18.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>5.880</td>\n",
       "      <td>97.3</td>\n",
       "      <td>2.3887</td>\n",
       "      <td>5.0</td>\n",
       "      <td>403.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>348.13</td>\n",
       "      <td>12.03</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ZN  INDUS  CHAS    NOX     RM    AGE     DIS   RAD    TAX  PTRATIO  \\\n",
       "29    0.0   8.14   0.0  0.538  6.674   87.3  4.2390   4.0  307.0     21.0   \n",
       "98    0.0   2.89   0.0  0.445  7.820   36.9  3.4952   2.0  276.0     18.0   \n",
       "310   0.0   9.90   0.0  0.544  4.973   37.8  2.5194   4.0  304.0     18.4   \n",
       "61   25.0   5.13   0.0  0.453  5.966   93.4  6.8185   8.0  284.0     19.7   \n",
       "185   0.0   2.46   0.0  0.488  6.153   68.8  3.2797   3.0  193.0     17.8   \n",
       "..    ...    ...   ...    ...    ...    ...     ...   ...    ...      ...   \n",
       "158   0.0  19.58   0.0  0.605  6.066  100.0  1.7573   5.0  403.0     14.7   \n",
       "415   0.0  18.10   0.0  0.679  6.434  100.0  1.8347  24.0  666.0     20.2   \n",
       "336   0.0   5.19   0.0  0.515  5.869   46.3  5.2311   5.0  224.0     20.2   \n",
       "60   25.0   5.13   0.0  0.453  5.741   66.2  7.2254   8.0  284.0     19.7   \n",
       "171   0.0  19.58   0.0  0.605  5.880   97.3  2.3887   5.0  403.0     14.7   \n",
       "\n",
       "          B  LSTAT  MEDV  \n",
       "29   380.23  11.98  21.0  \n",
       "98   393.53   3.57  43.8  \n",
       "310  350.45  12.64  16.1  \n",
       "61   378.08  14.44  16.0  \n",
       "185  387.11  13.15  29.6  \n",
       "..      ...    ...   ...  \n",
       "158  353.89   6.43  24.3  \n",
       "415   27.25  29.05   7.2  \n",
       "336  396.90   9.80  19.5  \n",
       "60   395.11  13.15  18.7  \n",
       "171  348.13  12.03  19.1  \n",
       "\n",
       "[102 rows x 13 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29      1.00245\n",
       "98      0.08187\n",
       "310     2.63548\n",
       "61      0.17171\n",
       "185     0.06047\n",
       "         ...   \n",
       "158     1.34284\n",
       "415    18.08460\n",
       "336     0.03427\n",
       "60      0.14932\n",
       "171     2.31390\n",
       "Name: TARGET, Length: 102, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make a new frame so its easier to keep features lined up with target values\n",
    "temp_frame = boston_frame.copy()\n",
    "temp_frame[\"TARGET\"] = t  # Remember we're using CRIM to predict, not the default dataset's MEDV\n",
    "\n",
    "\n",
    "# Split into training/testing sets\n",
    "training_data, testing_data = train_test_split(\n",
    "    temp_frame,\n",
    "    train_size = 0.8,\n",
    "    random_state = 483 # Reproducible outputs\n",
    ")\n",
    "\n",
    "# Pluck out the target values again\n",
    "training_targets = training_data[\"TARGET\"]\n",
    "del training_data[\"TARGET\"]\n",
    "testing_targets = testing_data[\"TARGET\"]\n",
    "del testing_data[\"TARGET\"]\n",
    "\n",
    "\n",
    "#\n",
    "print(\"Training data:\")\n",
    "display(training_data)\n",
    "print(\"Training targets:\")\n",
    "display(training_targets)\n",
    "print()\n",
    "\n",
    "#\n",
    "print(\"Testing data:\")\n",
    "display(testing_data)\n",
    "print(\"Testing targets:\")\n",
    "display(testing_targets)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4 - SKLearn; Fitting a Linear Regression\n",
    "Create and [fit()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.fit) an [sklearn.linear_model.LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression model:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.44837924582869015\n",
      "Y-Intercept: 19.898134955669544\n",
      "Coefficients (weights): [ 5.25078806e-02 -5.42967971e-02 -3.96176813e-01 -1.13839135e+01\n",
      "  7.78257737e-01  1.20580467e-02 -1.11171566e+00  6.28556740e-01\n",
      " -4.63804012e-03 -3.20866746e-01 -8.78829114e-03  2.34797170e-03\n",
      " -2.82009108e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "model = LinearRegression()\n",
    "\n",
    "\n",
    "# Fit the model to our training data\n",
    "model.fit(training_data, training_targets)\n",
    "\n",
    "\n",
    "#\n",
    "print(\"LinearRegression model:\")\n",
    "display(model)\n",
    "print(\"Score:\", model.score(boston_frame, t))\n",
    "print(\"Y-Intercept:\", model.intercept_)\n",
    "print(\"Coefficients (weights):\", model.coef_)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5 - Predict Some Values and Stuff\n",
    "Use the [predict()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.predict) method of the model to find the response for each value in the test set, and [sklearn.metrics.mean_squared_error()](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html), to find the training and test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training got a MSE of: 44.05110704502939\n",
      "Testing got a MSE of: 27.585112220532842\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Make predictions with our model, for both the training and testing data\n",
    "training_predictions = model.predict(training_data)\n",
    "testing_predictions = model.predict(testing_data)\n",
    "\n",
    "# print(\"Predictions based on training data:\")\n",
    "# display(training_predictions)\n",
    "# print(\"Predictions based on testing data:\")\n",
    "# display(testing_predictions)\n",
    "\n",
    "mse_training_ex5 = mean_squared_error(\n",
    "    y_true = training_targets,\n",
    "    y_pred = training_predictions\n",
    ")\n",
    "mse_testing_ex5 = mean_squared_error(\n",
    "    y_true = testing_targets,\n",
    "    y_pred = testing_predictions\n",
    ")\n",
    "print(\"Training got a MSE of:\", mse_training_ex5)\n",
    "print(\"Testing got a MSE of:\", mse_testing_ex5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6 - Coefficient of Determination\n",
    "By itself, the MSE doesn’t tell us much. Use the [score()](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html#sklearn.linear_model.LinearRegression.score) method of the model to find the $R^2$ values for the training and test data.\n",
    "\n",
    "$R^2$, the coefficient of determination, measures the proportion of variability in the target ***t*** that can be explained using the features in ***X***. A value near 1 indicates that most of the variability in the response has been explained by the regression, while a value near 0 indicates that the regression does not explain much of the variability. See Section 3.1.3 of *An Introduction to Statistical Learning for details*.\n",
    "\n",
    "***Question***: Given the $R^2$ scores, how well did our model do?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score against training data: 0.4528805078335282\n",
      "Model score against testing data: 0.4116070199986994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Ask the model to make predictions, then score itself against targets\n",
    "score_training_ex6 = model.score(X=training_data, y=training_targets)\n",
    "score_testing_ex6 = model.score(X=testing_data, y=testing_targets)\n",
    "\n",
    "print(\"Model score against training data:\", score_training_ex6)\n",
    "print(\"Model score against testing data:\", score_testing_ex6)\n",
    "print()\n",
    "\n",
    "\n",
    "##### HELLO PARTNER: Double check plz\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Experiment 6 Questions\n",
    "\n",
    "*Given the $R^2$ scores, how well did our model do?*\n",
    "\n",
    "Our model got an $R^2$ score of .41 for the testing, which means we are able to explain target values with features with an accuracy of less than half. Therefore, these features aren't really enough to explain the whole picture of the target values, and we probably need to use a lot more.\n",
    "\n",
    "Also, our score was lower for testing than training, so it's possible we're seeing a little overfitting (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7 - Polynomial Model\n",
    "Let’s see if we can fit the data better with a more flexible model. Scikit-learn can [construct polynomial features](https://scikit-learn.org/stable/modules/linear_model.html#polynomial-regression-extending-linear-models-with-basis-functions) for us using [sklearn.preprocessing.PolynomialFeatures](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html) (though note that this includes interaction features as well; you saw in Project 2 that purely polynomial features can easily be constructed using [numpy.hstack()](https://numpy.org/doc/stable/reference/generated/numpy.hstack.html)).\n",
    "\n",
    "Add degree-2 polynomial features, then fit a new linear model.\n",
    "\n",
    "***Question***: Compare the training and test MSE and $R^2$ scores. Do we seem to be overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original][Training] MSE: 44.05110704502939\n",
      "[Poly]    [Training] MSE: 24.791871089417047\n",
      "\n",
      "[Original][Testing] MSE: 27.585112220532842\n",
      "[Poly]    [Testing] MSE: 52.87430041788828\n",
      "\n",
      "\n",
      "[Original][Training] Score: 0.4528805078335282\n",
      "[Poly]    [Training] Score: 0.6920822919062365\n",
      "\n",
      "[Original][Testing] Score: 0.4116070199986994\n",
      "[Poly]    [Testing] Score: -0.1278136894874793\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instantiate a preprocessor that will give our data polynomial features of degree 2\n",
    "# Will also add interaction terms\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "\n",
    "# Use the preprocessor to create poly+interact data\n",
    "training_data_poly = poly.fit_transform(X=training_data)\n",
    "testing_data_poly = poly.fit_transform(X=testing_data)\n",
    "\n",
    "\n",
    "# Make a new model and fit it to our new poly data\n",
    "model_poly = LinearRegression()\n",
    "model_poly.fit(training_data_poly, training_targets)\n",
    "\n",
    "\n",
    "# Make predictions with our new poly model, for both the training and testing data\n",
    "training_predictions_poly = model_poly.predict(training_data_poly)\n",
    "testing_predictions_poly = model_poly.predict(testing_data_poly)\n",
    "\n",
    "\n",
    "# Compute the MSE's for the new poly model\n",
    "mse_training_poly_ex7 = mean_squared_error(\n",
    "    y_true = training_targets,\n",
    "    y_pred = training_predictions_poly\n",
    ")\n",
    "mse_testing_poly_ex7 = mean_squared_error(\n",
    "    y_true = testing_targets,\n",
    "    y_pred = testing_predictions_poly\n",
    ")\n",
    "\n",
    "\n",
    "# Compute the score for the new poly model, against both training and testing sets\n",
    "score_training_poly_ex7 = model_poly.score(X=training_data_poly, y=training_targets)\n",
    "score_testing_poly_ex7 = model_poly.score(X=testing_data_poly, y=testing_targets)\n",
    "\n",
    "\n",
    "print(\"[Original][Training] MSE:\", mse_training_ex5)\n",
    "print(\"[Poly]    [Training] MSE:\", mse_training_poly_ex7)\n",
    "print()\n",
    "print(\"[Original][Testing] MSE:\", mse_testing_ex5)\n",
    "print(\"[Poly]    [Testing] MSE:\", mse_testing_poly_ex7)\n",
    "print()\n",
    "print()\n",
    "print(\"[Original][Training] Score:\", score_training_ex6)\n",
    "print(\"[Poly]    [Training] Score:\", score_training_poly_ex7)\n",
    "print()\n",
    "print(\"[Original][Testing] Score:\", score_testing_ex6)\n",
    "print(\"[Poly]    [Testing] Score:\", score_testing_poly_ex7)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Experiment 7 Questions\n",
    "\n",
    "* Compare the training and test MSE and $R^2$ scores. Do we seem to be overfitting? *\n",
    "\n",
    "The polynomial (plus interactions) model definitely seems to be overfitting. The training set shows both that the MSE and Score is better for the poly model, but those scores drop dramatically once we measure the model against the testing set.\n",
    "\n",
    "The model's score for the testing set even goes hilariously into the negative, suggesting the model's input feature set explains \"less than nothing\" of the target output set, which I take to mean \"this is even worse than if you had just made random predictions\".\n",
    "\n",
    "The above suggests we are definitely overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 8 - Regularization\n",
    "Regularization would allow us to construct a model of intermediate complexity by penalizing large values for the coefficients. Scikit-learn provides this as [sklearn.linear_model.Ridge](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html). The parameter alpha corresponds to 𝜆 as shown in the textbook. For now, leave it set to the default value of 1.0, and fit the model to the degree-2 polynomial features. Don’t forget to normalize your features.\n",
    "\n",
    "Once again, compare the training and test MSE and $R^2$ scores.\n",
    "\n",
    "***Question***: Is this model an improvement?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original][Training] MSE: 44.05110704502939\n",
      "[Poly]    [Training] MSE: 24.791871089417047\n",
      "[Ridge]   [Training] MSE: 41.44595282614817\n",
      "\n",
      "[Original][Testing] MSE: 27.585112220532842\n",
      "[Poly]    [Testing] MSE: 52.87430041788828\n",
      "[Ridge]   [Testing] MSE: 20.529150436028058\n",
      "\n",
      "\n",
      "[Original][Training] Score: 0.4528805078335282\n",
      "[Poly]    [Training] Score: 0.6920822919062365\n",
      "[Ridge]   [Training] Score: 0.48523680371032984\n",
      "\n",
      "[Original][Testing] Score: 0.4116070199986994\n",
      "[Poly]    [Testing] Score: -0.1278136894874793\n",
      "[Ridge]   [Testing] Score: 0.5621113336287809\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Build a regularized model using scklearn.linear_model.Ridge()\n",
    "# Professor wants us to normalize data, which I'm assuming just means set the normalize parameter here\n",
    "# ***** HEY PARTNER WADDAYA THINK? *****\n",
    "model_ridge = Ridge(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "# Fit to the poly+interactive training set\n",
    "model_ridge.fit(training_data_poly, training_targets)\n",
    "\n",
    "# Make predictions with our new ridge model, for both the training and testing data\n",
    "training_predictions_ridge = model_ridge.predict(training_data_poly)\n",
    "testing_predictions_ridge = model_ridge.predict(testing_data_poly)\n",
    "\n",
    "\n",
    "# Compute the MSE's for the new ridge model\n",
    "mse_training_ridge_ex8 = mean_squared_error(\n",
    "    y_true = training_targets,\n",
    "    y_pred = training_predictions_ridge\n",
    ")\n",
    "mse_testing_ridge_ex8 = mean_squared_error(\n",
    "    y_true = testing_targets,\n",
    "    y_pred = testing_predictions_ridge\n",
    ")\n",
    "\n",
    "\n",
    "# Compute the score for the new ridge model, against both training and testing sets\n",
    "score_training_ridge_ex8 = model_ridge.score(X=training_data_poly, y=training_targets)\n",
    "score_testing_ridge_ex8 = model_ridge.score(X=testing_data_poly, y=testing_targets)\n",
    "\n",
    "\n",
    "print(\"[Original][Training] MSE:\", mse_training_ex5)\n",
    "print(\"[Poly]    [Training] MSE:\", mse_training_poly_ex7)\n",
    "print(\"[Ridge]   [Training] MSE:\", mse_training_ridge_ex8)\n",
    "print()\n",
    "print(\"[Original][Testing] MSE:\", mse_testing_ex5)\n",
    "print(\"[Poly]    [Testing] MSE:\", mse_testing_poly_ex7)\n",
    "print(\"[Ridge]   [Testing] MSE:\", mse_testing_ridge_ex8)\n",
    "print()\n",
    "print()\n",
    "print(\"[Original][Training] Score:\", score_training_ex6)\n",
    "print(\"[Poly]    [Training] Score:\", score_training_poly_ex7)\n",
    "print(\"[Ridge]   [Training] Score:\", score_training_ridge_ex8)\n",
    "print()\n",
    "print(\"[Original][Testing] Score:\", score_testing_ex6)\n",
    "print(\"[Poly]    [Testing] Score:\", score_testing_poly_ex7)\n",
    "print(\"[Ridge]   [Testing] Score:\", score_testing_ridge_ex8)\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Experiment 8 Questions\n",
    "\n",
    "* Once again, compare the training and test MSE and R2 scores. Is this model an improvement? *\n",
    "\n",
    "The ridge model shows huge improvement over both the non-polynomial model, and the polynomial model!\n",
    "\n",
    "You can see the MSE for the Ridge model against the training set isn't much lower than the normal model, but its benefit jumps up significantly when it shows up with the lowest MSE against the testing set of all three models, by a significant margin.\n",
    "\n",
    "The Ridge model is also a significant improvement over the normal model, and obviously a huge improvement over the laughably-inept poly model. This tells us that the true model probably lies somewhere in between the original normal model and the 2nd degree poly model we chose. We were previously unable to access this optimized \"middle ground\" point, but the Ridge model has unlocked it for us!\n",
    "\n",
    "TL;DR: Yes definitely an improvement.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 9\n",
    "We used the default penalty value of 1.0 in the previous experiment, but there’s no reason to believe that this is optimal. Use [sklearn.linear_model.RidgeCV](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeCV.html) to find an optimal value for alpha.\n",
    "\n",
    "***Question***: How does this compare to experiment (8)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original][Training] MSE: 44.05110704502939\n",
      "[Poly]    [Training] MSE: 24.791871089417047\n",
      "[Ridge]   [Training] MSE: 41.44595282614817\n",
      "[Ridge CV][Training] MSE: 36.482968190330595\n",
      "\n",
      "[Original][Testing] MSE: 27.585112220532842\n",
      "[Poly]    [Testing] MSE: 52.87430041788828\n",
      "[Ridge]   [Testing] MSE: 20.529150436028058\n",
      "[Ridge CV][Testing] MSE: 18.259117051180002\n",
      "\n",
      "\n",
      "[Original][Training] Score: 0.4528805078335282\n",
      "[Poly]    [Training] Score: 0.6920822919062365\n",
      "[Ridge]   [Training] Score: 0.48523680371032984\n",
      "[Ridge CV][Training] Score: 0.5468776072161956\n",
      "\n",
      "[Original][Testing] Score: 0.4116070199986994\n",
      "[Poly]    [Testing] Score: -0.1278136894874793\n",
      "[Ridge]   [Testing] Score: 0.5621113336287809\n",
      "[Ridge CV][Testing] Score: 0.6105313544478002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# First, generate a bunch of alpha values to try. We want to try more than the defaults.\n",
    "alphas_to_try = []\n",
    "one_alpha = 0.1\n",
    "while one_alpha <= 10.0:\n",
    "    alphas_to_try.append(one_alpha)\n",
    "    one_alpha += 0.1\n",
    "print(\"Will try the following alpha values:\")\n",
    "print(alphas_to_try)\n",
    "print()\n",
    "\n",
    "\n",
    "# Next, use the RidgeCV model, which is basically just the Ridge model,\n",
    "#  but using cross-validation to determine which alpha is best to use\n",
    "model_ridge_cv = RidgeCV(\n",
    "    alphas=alphas_to_try,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "\n",
    "# Fit to the poly+interactive training set\n",
    "model_ridge_cv.fit(training_data_poly, training_targets)\n",
    "\n",
    "\n",
    "# Make predictions with our new ridge CV model, for both the training and testing data\n",
    "training_predictions_ridge_cv = model_ridge_cv.predict(training_data_poly)\n",
    "testing_predictions_ridge_cv = model_ridge_cv.predict(testing_data_poly)\n",
    "\n",
    "\n",
    "# Compute the MSE's for the new ridge model\n",
    "mse_training_ridge_cv_ex9 = mean_squared_error(\n",
    "    y_true = training_targets,\n",
    "    y_pred = training_predictions_ridge_cv\n",
    ")\n",
    "mse_testing_ridge_cv_ex9 = mean_squared_error(\n",
    "    y_true = testing_targets,\n",
    "    y_pred = testing_predictions_ridge_cv\n",
    ")\n",
    "\n",
    "\n",
    "# Compute the score for the new ridge model, against both training and testing sets\n",
    "score_training_ridge_cv_ex9 = model_ridge_cv.score(X=training_data_poly, y=training_targets)\n",
    "score_testing_ridge_cv_ex9 = model_ridge_cv.score(X=testing_data_poly, y=testing_targets)\n",
    "\n",
    "\n",
    "print(\"[Original][Training] MSE:\", mse_training_ex5)\n",
    "print(\"[Poly]    [Training] MSE:\", mse_training_poly_ex7)\n",
    "print(\"[Ridge]   [Training] MSE:\", mse_training_ridge_ex8)\n",
    "print(\"[Ridge CV][Training] MSE:\", mse_training_ridge_cv_ex9)\n",
    "print()\n",
    "print(\"[Original][Testing] MSE:\", mse_testing_ex5)\n",
    "print(\"[Poly]    [Testing] MSE:\", mse_testing_poly_ex7)\n",
    "print(\"[Ridge]   [Testing] MSE:\", mse_testing_ridge_ex8)\n",
    "print(\"[Ridge CV][Testing] MSE:\", mse_testing_ridge_cv_ex9)\n",
    "print()\n",
    "print()\n",
    "print(\"[Original][Training] Score:\", score_training_ex6)\n",
    "print(\"[Poly]    [Training] Score:\", score_training_poly_ex7)\n",
    "print(\"[Ridge]   [Training] Score:\", score_training_ridge_ex8)\n",
    "print(\"[Ridge CV][Training] Score:\", score_training_ridge_cv_ex9)\n",
    "print()\n",
    "print(\"[Original][Testing] Score:\", score_testing_ex6)\n",
    "print(\"[Poly]    [Testing] Score:\", score_testing_poly_ex7)\n",
    "print(\"[Ridge]   [Testing] Score:\", score_testing_ridge_ex8)\n",
    "print(\"[Ridge CV][Testing] Score:\", score_testing_ridge_cv_ex9)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answering Experiment 9 Questions\n",
    "\n",
    "* How does this compare to experiment (8)? *\n",
    "\n",
    "We get even better scores! The MSE is the lowest yet against the test set, of all the models. The score also shows that our input features explain the target values the most yet, out of any previous model.\n",
    "\n",
    "It appears cross-validation is a great way to fine-tune the correct alpha score.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
